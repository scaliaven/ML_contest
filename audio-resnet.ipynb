{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n",
      "12.1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import crop\n",
    "import gc\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42) \n",
    "import os\n",
    "gc.collect()\n",
    "\n",
    "#from torchvision.transforms import v2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(device)\n",
    "\n",
    "transform_1 = transforms.Compose(\n",
    "    [\n",
    "#     transforms.Lambda(crop_image),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.AugMix(),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "    ])\n",
    "\n",
    "transform_2 = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((64, 64)),\n",
    "        transforms.AugMix(),\n",
    "    transforms.RandomHorizontalFlip(1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "    ])\n",
    "\n",
    "transform_3 = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((64, 64)),\n",
    "        transforms.AugMix(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision.io.image import read_file\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, idex_list, transform=None, mask = None, balance = False):\n",
    "        with open(annotations_file, 'r') as file:\n",
    "            content = file.read()\n",
    "            lines = content.strip(\"\\n\").split('\\n')        \n",
    "        self.img_labels_init = []\n",
    "        for index in idex_list:\n",
    "            self.img_labels_init.append(lines[index])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.idex_list = idex_list\n",
    "        self.image = []\n",
    "        self.mask = mask\n",
    "        self.img_labels = []\n",
    "        for idx in tqdm(range(len(self.idex_list))):\n",
    "            label = self.img_labels_init[idx]\n",
    "            img_path = os.path.join(self.img_dir, f\"{self.idex_list[idx]}.png\")\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.mask:\n",
    "                image = image[:, :, self.mask]\n",
    "            if balance: \n",
    "                if label == '0':\n",
    "                    for i in range(3):\n",
    "                        self.image.append(image)\n",
    "                        self.img_labels.append(label)\n",
    "            self.img_labels.append(label)\n",
    "            self.image.append(image)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = int(self.img_labels[idx])\n",
    "        image = self.image[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# with open(\"/scratch/hh3043/ML_contest/dataset/train_label.txt\", 'r') as file:\n",
    "#     content = file.read()\n",
    "#     num = len(content.strip(\"\\n\").split('\\n'))\n",
    "    \n",
    "    \n",
    "# train_data_idx, test_data_idx = train_test_split(list(range(num)), test_size=0.2, random_state=42)\n",
    "\n",
    "total_data = CustomImageDataset(\"/scratch/hh3043/ML_contest/dataset/train_label.txt\", \"/scratch/hh3043/ML_contest/dataset/train_img\", train_data_idx, transform=transform, mask = None, balance = True)\n",
    "test_data = CustomImageDataset(\"/scratch/hh3043/ML_contest/dataset/train_label.txt\", \"/scratch/hh3043/ML_contest/dataset/train_img\", test_data_idx, transform=transform, mask = None, balance = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    image = torch.stack([x[0] for x in batch])\n",
    "    label = torch.tensor([x[1] for x in batch])\n",
    "    return image, label\n",
    "\n",
    "total_data = torch.load('/scratch/hh3043/ML_contest/dataset/total_train_32.pt') \n",
    "t_data = torch.load('/scratch/hh3043/ML_contest/dataset/total_train_32_1.pt') \n",
    "total_data = ConcatDataset([total_data, t_data])\n",
    "test_data = torch.load('/scratch/hh3043/ML_contest/dataset/total_test_32.pt')\n",
    "print(\"Finished loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# trainloader = DataLoader(total_data, batch_size=16, shuffle=True, num_workers=3)\n",
    "# testloader = DataLoader(test_data, batch_size=16, shuffle=False, num_workers=3)\n",
    "\n",
    "trainloader = DataLoader(total_data, batch_size=16, collate_fn=collate_fn, shuffle=True, num_workers=3)\n",
    "testloader = DataLoader(test_data, batch_size=16, collate_fn=collate_fn, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "def res(input_channel):\n",
    "    block = nn.Sequential(\n",
    "          nn.Conv2d(input_channel,input_channel,3, padding = 1),\n",
    "          nn.BatchNorm2d(input_channel),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(input_channel,input_channel,3, padding = 1),\n",
    "          nn.BatchNorm2d(input_channel),\n",
    "        )\n",
    "    \n",
    "    return nn.Sequential(*block)\n",
    "\n",
    "def conv_block(input_channel, output_channel, filter_size = 3,padding = 1):\n",
    "    block = nn.Sequential(\n",
    "          nn.Conv2d(input_channel,output_channel,filter_size, padding = padding),\n",
    "          nn.BatchNorm2d(output_channel),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    return nn.Sequential(*block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the whole network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "\n",
    "        self.conv1 = conv_block(3, 64, 7, padding = 3)\n",
    "        self.res1_1 = res(64)\n",
    "        self.res1_2 = res(64)\n",
    "        self.res1_3 = res(64)\n",
    "        \n",
    "        self.conv2 = conv_block(64, 128, 3, padding = 1)\n",
    "        self.res2_1 = res(128)\n",
    "        self.res2_2 = res(128)\n",
    "        self.res2_3 = res(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.res3_1 = res(256)\n",
    "        self.res3_2 = res(256)\n",
    "        self.res3_3 = res(256)\n",
    "       \n",
    "        self.conv4 = nn.Conv2d(256, 512, 3, padding = 1)\n",
    "        self.res4_1 = res(512)\n",
    "        self.res4_2 = res(512)\n",
    "        self.res4_3 = res(512)\n",
    "        \n",
    "        self.droup = nn.Dropout(0.2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 4)\n",
    "        self.fc2 = nn.Linear(400, 4)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.res1_1(x) + x)\n",
    "        x = F.relu(self.res1_2(x) + x)\n",
    "        #x = F.relu(self.res1_3(x) + x)\n",
    "        \n",
    "#         x = self.droup(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.res2_1(x) + x)\n",
    "        x = F.relu(self.res2_2(x) + x)\n",
    "        #x = F.relu(self.res2_3(x) + x)\n",
    "        \n",
    "        # x = self.droup(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.res3_1(x) + x)\n",
    "        x = F.relu(self.res3_2(x) + x)\n",
    "        #x = F.relu(self.res3_3(x) + x)\n",
    "        \n",
    "#         x = self.droup(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.res4_1(x) + x)\n",
    "        x = F.relu(self.res4_2(x) + x)\n",
    "        #x = F.relu(self.res4_3(x) + x)\n",
    "        \n",
    "#         x = self.droup(x)\n",
    "\n",
    "        #print(x.size())\n",
    "        x = x.view(-1, 512 * 4 * 4)\n",
    "        x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "        x = nn.Softmax(dim=1)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "# PATH = \"/kaggle/input/audio_resnet/pytorch/httpswww.kaggle.commodelshongjiahuangaudio_resnetpytorch/7/checkpoint_64_27.pth\"\n",
    "# net.load_state_dict(torch.load(PATH)['state_dict'])\n",
    "net.to(device)  # gpu/ cpu\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "max_lr = 0.01\n",
    "epochs = 22\n",
    "optimizer = optim.SGD(net.parameters(), lr = max_lr, weight_decay = 1.0e-4, momentum = 0.9) \n",
    "grad_clip = 0.1\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs*len(trainloader))\n",
    "criterion = criterion.cuda()\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "class test_CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(1 for file in Path(self.img_dir).iterdir() if file.suffix == '.png')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, f\"{idx}.png\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(net, testloader, criterion):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    val_loss =running_loss/len(testloader)\n",
    "    print(f'validation Loss:{val_loss:.2f}, accuracy: {accuracy:.2f}%')\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.003 | Accuracy: 73.686 | lr: 0.000398 | validation Loss:1.02, accuracy: 71.87%\n",
      "Train Loss: 0.905 | Accuracy: 83.635 | lr: 0.000392 | validation Loss:0.96, accuracy: 78.01%\n",
      "Train Loss: 0.849 | Accuracy: 89.353 | lr: 0.000382 | validation Loss:0.96, accuracy: 78.09%\n",
      "Train Loss: 0.817 | Accuracy: 92.605 | lr: 0.000368 | validation Loss:0.93, accuracy: 81.12%\n",
      "Train Loss: 0.796 | Accuracy: 94.697 | lr: 0.000351 | validation Loss:0.92, accuracy: 82.34%\n",
      "Train Loss: 0.784 | Accuracy: 95.980 | lr: 0.000331 | validation Loss:0.93, accuracy: 80.95%\n",
      "Train Loss: 0.777 | Accuracy: 96.667 | lr: 0.000308 | validation Loss:0.91, accuracy: 83.56%\n",
      "Train Loss: 0.772 | Accuracy: 97.179 | lr: 0.000283 | validation Loss:0.91, accuracy: 82.59%\n",
      "Train Loss: 0.770 | Accuracy: 97.380 | lr: 0.000256 | validation Loss:0.91, accuracy: 83.26%\n",
      "Train Loss: 0.769 | Accuracy: 97.500 | lr: 0.000228 | validation Loss:0.91, accuracy: 83.60%\n",
      "Train Loss: 0.768 | Accuracy: 97.565 | lr: 0.000200 | validation Loss:0.91, accuracy: 83.77%\n",
      "Train Loss: 0.768 | Accuracy: 97.612 | lr: 0.000172 | validation Loss:0.91, accuracy: 83.22%\n",
      "Train Loss: 0.767 | Accuracy: 97.666 | lr: 0.000144 | validation Loss:0.91, accuracy: 83.39%\n",
      "Finished Training last_learning_rate 0.00014365348863170792\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_val = 100\n",
    "cnt = 0\n",
    "patience = 6\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct=0\n",
    "    total=0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # inputs, labels = data\n",
    "        #inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, 0.2)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_value_(net.parameters(), grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        #sched.step()\n",
    "        scheduler.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "    train_loss =running_loss/len(trainloader)\n",
    "    accu=100.*correct/total\n",
    "\n",
    "    #train_accu.append(accu)\n",
    "    #train_losses.append(train_loss)\n",
    "    my_lr = scheduler.get_last_lr()[0]\n",
    "    print('Train Loss: %.3f | Accuracy: %.3f | lr: %f'%(train_loss,accu, my_lr), end = \" | \")\n",
    "    val_loss, _ =testing(net, testloader, criterion)\n",
    "    if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "    else:\n",
    "        cnt += 1\n",
    "        if cnt >= patience:\n",
    "            break\n",
    "    \n",
    "my_lr = scheduler.get_last_lr()[0]\n",
    "print('Finished Training', \"last_learning_rate\", my_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss:0.91, accuracy: 83.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9077153581900884, 83.38940285954584)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(net, testloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_loader = DataLoader(ConcatDataset([total_data , test_data]), batch_size=16, shuffle=True, num_workers=3)  #ConcatDataset([train_data_1,train_data_4]) train_data_2, train_data_3, \n",
    "# epochs = 3\n",
    "# for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "#     net.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct=0\n",
    "#     total=0\n",
    "\n",
    "#     for i, data in enumerate(total_loader, 0):\n",
    "#         # get the inputs\n",
    "#         inputs, labels = data\n",
    "#         inputs, labels = inputs.to(device), labels.to(device) # inputs, labels = data\n",
    "#         #inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, 0.2)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         # loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_value_(net.parameters(), grad_clip)\n",
    "        \n",
    "#         optimizer.step()\n",
    "#         #sched.step()\n",
    "#         scheduler.step()\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "#     train_loss =running_loss/len(total_loader)\n",
    "#     accu=100.*correct/total\n",
    "\n",
    "#     #train_accu.append(accu)\n",
    "#     #train_losses.append(train_loss)\n",
    "#     my_lr = scheduler.get_last_lr()[0]\n",
    "#     print('Train Loss: %.3f | Accuracy: %.3f | lr: %f'%(train_loss,accu, my_lr))\n",
    "# my_lr = scheduler.get_last_lr()[0]\n",
    "# print('Finished Training', \"last_learning_rate\", my_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': Net(),\n",
    "              'state_dict': net.state_dict(),\n",
    "              'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, '/scratch/hh3043/ML_contest/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "test_data = test_CustomImageDataset(\"/scratch/hh3043/ML_contest/dataset/test_img\", transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False, num_workers=3)\n",
    "\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images = data\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        \n",
    "output = pd.DataFrame({\n",
    "\"id\": [i for i in range(len(test_data))],\n",
    "\"category\": predicted_labels\n",
    "})\n",
    "\n",
    "output.to_csv('/scratch/hh3043/ML_contest/my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4878639,
     "sourceId": 8241866,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4878592,
     "sourceId": 8241880,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 33411,
     "sourceId": 40324,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
